{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ef3bc25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import config\n",
    "from db_manager import DBManager\n",
    "import os\n",
    "from rest_api import Api\n",
    "from datetime import date, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from urllib.parse import quote_plus\n",
    "from sqlalchemy import create_engine\n",
    "import itertools\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce43a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(levelname)s-%(lineno)s-%(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level='INFO'\n",
    ")\n",
    "logger=logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e031de87",
   "metadata": {},
   "source": [
    "#### Show all columns without truncating"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2111e1",
   "metadata": {},
   "source": [
    "Today's date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a6455f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:2-Current date: 2023-10-02\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "logger.info(f'Current date: {today}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1821b741",
   "metadata": {},
   "source": [
    "Adding months to today's date. Near term travel dates 30 - 60 days ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "15c6c73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:5-Departure_dates:2023-11-02 and 2023-12-02 \n",
      "Return dates:2023-12-02 and 2024-01-02\n"
     ]
    }
   ],
   "source": [
    "departure_date_1_month = today + relativedelta(months=1)\n",
    "departure_date_2_month = today + relativedelta(months=2)\n",
    "return_date_1_month = departure_date_2_month\n",
    "return_date_2_month = today + relativedelta(months=3)\n",
    "logger.info(f'Departure_dates:{departure_date_1_month} and {departure_date_2_month} \\nReturn dates:{return_date_1_month} and {return_date_2_month}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8dab2b",
   "metadata": {},
   "source": [
    "Get the nearby festival departure dates by start_date from the public.indian_holidays table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d09bcf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials=config.pg_credentials\n",
    "# db = DBManager(credentials=credentials)\n",
    "# df_departure_arrival_dates = db.run_query(query_file_name='festival_dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b746da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_departure_arrival_dates "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d872d1",
   "metadata": {},
   "source": [
    "Apply the combination of params to get data for all possible combinations of depart, arrival dates and depart arrival airports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8144963f",
   "metadata": {},
   "source": [
    "Combination itertools usage. Im calculating the total combinations by multiplying the number of possibilities (unique values) for each variable<br />\n",
    "Departure airport: 2 possibilities<br />\n",
    "Arrival airport: 4 possibilities<br />\n",
    "Departure date: 2 possibilities<br />\n",
    "Arrival date: 1 possibilities<br />\n",
    "Total combinations = 2 x 4 x 2 x 1 = 16 combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e128a2",
   "metadata": {},
   "source": [
    "#### Travel payouts API to get flight search results for each combination in the list "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8058c0cf",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fca752f6",
   "metadata": {},
   "source": [
    "API test for amadeus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a235c41a",
   "metadata": {},
   "source": [
    "POST request to the Amadeus authorization server to get the access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0dc9be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:6-Successful access token generation\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=config.url_token, headers=config.headers_token, data=config.data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "  # API call succeeded\n",
    "  token = response.json()['access_token'] \n",
    "  logger.info('Successful access token generation')\n",
    "else:\n",
    "  # API call failed\n",
    "  print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b89d1abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinations of destination and origin airport codes\n",
    "origins = config.params['originLocationCode']\n",
    "destinations = config.params['destinationLocationCode']\n",
    "departure_dates=[departure_date_1_month,departure_date_2_month]\n",
    "# return_dates=[return_date_1_month,return_date_2_month]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7771296",
   "metadata": {},
   "source": [
    "Creating combinations of Origin and Destination to be passed as parameters to the api call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ba676b",
   "metadata": {},
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bf314de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:35-API call 1 succeeded for flight offers\n",
      "INFO-__main__:35-API call 2 succeeded for flight offers\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:35-API call 3 succeeded for flight offers\n",
      "INFO-__main__:35-API call 4 succeeded for flight offers\n",
      "INFO-__main__:35-API call 5 succeeded for flight offers\n",
      "INFO-__main__:35-API call 6 succeeded for flight offers\n",
      "INFO-__main__:35-API call 7 succeeded for flight offers\n",
      "INFO-__main__:35-API call 8 succeeded for flight offers\n",
      "INFO-__main__:35-API call 9 succeeded for flight offers\n",
      "INFO-__main__:35-API call 10 succeeded for flight offers\n",
      "INFO-__main__:35-API call 11 succeeded for flight offers\n",
      "INFO-__main__:35-API call 12 succeeded for flight offers\n",
      "INFO-__main__:35-API call 13 succeeded for flight offers\n",
      "INFO-__main__:35-API call 14 succeeded for flight offers\n",
      "INFO-__main__:35-API call 15 succeeded for flight offers\n",
      "INFO-__main__:35-API call 16 succeeded for flight offers\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "  'client_id': config.client_id, \n",
    "  'client_secret': config.client_secret,\n",
    "  'Authorization': f'Bearer {token}'\n",
    "  }\n",
    "\n",
    "url = config.url\n",
    "\n",
    "response = []\n",
    "counter = 0\n",
    "\n",
    "for origin, dest, depart in itertools.product(origins, destinations, departure_dates):\n",
    "\n",
    "    params={\n",
    "        'originLocationCode': origin,\n",
    "        'destinationLocationCode':dest, \n",
    "        'departureDate': depart, \n",
    "        'returnDate' : None,\n",
    "        'adults':1,\n",
    "        'children':None,\n",
    "        'infants':None,\n",
    "        'travelClass':None,\n",
    "        'currencyCode':'EUR',\n",
    "        'maxPrice' : None\n",
    "        }\n",
    "\n",
    "\n",
    "    #to be worked on later for by calling rest_api module\n",
    "    # api = Api()\n",
    "    # resp = api.make_flight_api_request(url,headers,params)\n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    counter = counter+1\n",
    "    resp = resp.json()\n",
    "    response.append(resp)\n",
    "    logger.info(f'API call {counter} succeeded for flight offers')\n",
    "    # else:\n",
    "    #     # API call failed\n",
    "    #     logger.info('API call failed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff80cd7",
   "metadata": {},
   "source": [
    "Convert that sample nested JSON data into separate DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3905289",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flight offers DataFrame\n",
    "for r in response: \n",
    "    offers_df = pd.DataFrame(r['data'])\n",
    "    # Itineraries DataFrame\n",
    "    itineraries_df = pd.json_normalize(r['data'], record_path='itineraries', meta=['id', 'source'])\n",
    "    # # Traveler pricing DataFrame\n",
    "    traveler_pricing_df = pd.json_normalize(r['data'], record_path=['travelerPricings'], meta=['id', 'source'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c03b0c",
   "metadata": {},
   "source": [
    "Treating the itineraries df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7db9495",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'segment' column to create separate rows for each dictionary\n",
    "exploded_df = itineraries_df.explode('segments')\n",
    "\n",
    "# Split the dictionary into columns  \n",
    "df2 = exploded_df['segments'].apply(pd.Series)\n",
    "\n",
    "# Merge the new columns back to the original DataFrame\n",
    "df = exploded_df.merge(df2, right_index=True, left_index=True, suffixes=('_original', '_segments'))\n",
    "\n",
    "# Drop the original dictionary column\n",
    "df = df.drop(columns=['segments']) \n",
    "df = df.rename(columns={'duration_original': 'duration_total'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6af7f41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_total</th>\n",
       "      <th>id_original</th>\n",
       "      <th>source</th>\n",
       "      <th>carrierCode</th>\n",
       "      <th>number</th>\n",
       "      <th>duration_segments</th>\n",
       "      <th>id_segments</th>\n",
       "      <th>numberOfStops</th>\n",
       "      <th>dept_airport</th>\n",
       "      <th>dept_at</th>\n",
       "      <th>arrival_airport</th>\n",
       "      <th>arrival_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT18H25M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>UK</td>\n",
       "      <td>26</td>\n",
       "      <td>PT6H40M</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2023-12-02T21:20:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2023-12-03T08:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT18H25M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>UK</td>\n",
       "      <td>837</td>\n",
       "      <td>PT2H50M</td>\n",
       "      <td>81</td>\n",
       "      <td>0</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2023-12-03T17:25:00</td>\n",
       "      <td>MAA</td>\n",
       "      <td>2023-12-03T20:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT20H55M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>UK</td>\n",
       "      <td>26</td>\n",
       "      <td>PT6H40M</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2023-12-02T21:20:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2023-12-03T08:30:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT20H55M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>UK</td>\n",
       "      <td>835</td>\n",
       "      <td>PT2H50M</td>\n",
       "      <td>151</td>\n",
       "      <td>0</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2023-12-03T19:55:00</td>\n",
       "      <td>MAA</td>\n",
       "      <td>2023-12-03T22:45:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT32H20M</td>\n",
       "      <td>3</td>\n",
       "      <td>GDS</td>\n",
       "      <td>UK</td>\n",
       "      <td>26</td>\n",
       "      <td>PT6H40M</td>\n",
       "      <td>73</td>\n",
       "      <td>0</td>\n",
       "      <td>FRA</td>\n",
       "      <td>2023-12-02T21:20:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2023-12-03T08:30:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration_total id_original source carrierCode number duration_segments  \\\n",
       "0       PT18H25M           1    GDS          UK     26           PT6H40M   \n",
       "1       PT18H25M           1    GDS          UK    837           PT2H50M   \n",
       "2       PT20H55M           2    GDS          UK     26           PT6H40M   \n",
       "3       PT20H55M           2    GDS          UK    835           PT2H50M   \n",
       "4       PT32H20M           3    GDS          UK     26           PT6H40M   \n",
       "\n",
       "  id_segments  numberOfStops dept_airport              dept_at  \\\n",
       "0          80              0          FRA  2023-12-02T21:20:00   \n",
       "1          81              0          DEL  2023-12-03T17:25:00   \n",
       "2         150              0          FRA  2023-12-02T21:20:00   \n",
       "3         151              0          DEL  2023-12-03T19:55:00   \n",
       "4          73              0          FRA  2023-12-02T21:20:00   \n",
       "\n",
       "  arrival_airport           arrival_at  \n",
       "0             DEL  2023-12-03T08:30:00  \n",
       "1             MAA  2023-12-03T20:15:00  \n",
       "2             DEL  2023-12-03T08:30:00  \n",
       "3             MAA  2023-12-03T22:45:00  \n",
       "4             DEL  2023-12-03T08:30:00  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract departure keys using apply\n",
    "df['dept_airport'] = df['departure'].apply(lambda x: x['iataCode'])\n",
    "df['dept_at'] = df['departure'].apply(lambda x: x['at'])\n",
    "df['arrival_airport'] = df['arrival'].apply(lambda x: x['iataCode'])\n",
    "df['arrival_at'] = df['arrival'].apply(lambda x: x['at'])\n",
    "df['aircraft'] = df['aircraft'].apply(lambda x: x['code'])\n",
    "df.head()\n",
    "# Drop stops column if it exists\n",
    "column_to_drop = 'stops'\n",
    "if column_to_drop in df.columns:\n",
    "    df.drop(column_to_drop,axis=1,inplace=True)\n",
    "itineraries_df = df.drop(columns=['departure','arrival','operating','aircraft','blacklistedInEU'])\n",
    "\n",
    "itineraries_df = itineraries_df.drop_duplicates()\n",
    "# Reset index\n",
    "itineraries_df = itineraries_df.reset_index(drop=True)\n",
    "itineraries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2464c9bd",
   "metadata": {},
   "source": [
    "Finding out which columns in a dataframe are lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fbb5abba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming deduplicated_df is your DataFrame\n",
    "# list_columns = []\n",
    "\n",
    "# for column in final_df.columns:\n",
    "#     if final_df[column].apply(lambda x: isinstance(x, list)).any():\n",
    "#         list_columns.append(column)\n",
    "\n",
    "# print(\"Columns with lists:\", list_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39e311f",
   "metadata": {},
   "source": [
    "Treating traveler_pricing_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77ac0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'segment' column to create separate rows for each dictionary\n",
    "exploded_df = traveler_pricing_df.explode('fareDetailsBySegment')\n",
    "\n",
    "# Apply json_normalize to the 'segment' column to split dictionaries into separate columns\n",
    "normalized_df = json_normalize(exploded_df['fareDetailsBySegment']).add_suffix('_fare')\n",
    "\n",
    "# Join the exploded and normalized DataFrames\n",
    "final_df = exploded_df.drop('fareDetailsBySegment', axis=1).join(normalized_df)\n",
    "\n",
    "# Drop duplicates based on all columns to deduplicate the DataFrame\n",
    "deduplicated_df = final_df.drop_duplicates()\n",
    "\n",
    "# # If you want to reset the index of the deduplicated DataFrame\n",
    "deduplicated_df.reset_index(drop=True, inplace=True)\n",
    "# deduplicated_df=deduplicated_df.drop(columns=['id_segments'])\n",
    "\n",
    "# # Remove the added '_segment' suffix from column names\n",
    "deduplicated_df.columns = deduplicated_df.columns.str.replace('_fare$', '', regex=True)\n",
    "\n",
    "# #replace . in column anmes by underscore\n",
    "deduplicated_df.columns = deduplicated_df.columns.str.replace('.', '_', regex=False)\n",
    "\n",
    "# #Assigning to itineraries df\n",
    "traveler_pricing_df = deduplicated_df\n",
    "\n",
    "# #drop unwanted columns \n",
    "traveler_pricing_df=traveler_pricing_df.drop(columns=['fareBasis','class','brandedFare'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee74de9",
   "metadata": {},
   "source": [
    "---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e8edd468",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:2-Current date: 2023-10-02 23:28:09.203598\n"
     ]
    }
   ],
   "source": [
    "now = datetime.now()\n",
    "logger.info(f'Current date: {now}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb73b11",
   "metadata": {},
   "source": [
    "Dropping unwanted columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "28554477",
   "metadata": {},
   "outputs": [],
   "source": [
    "itineraries_df['incremental_day']=now\n",
    "traveler_pricing_df['incremental_day']=now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "96ba399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected!\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "Execution failed on sql '\n        SELECT\n            name\n        FROM\n            sqlite_master\n        WHERE\n            type IN ('table', 'view')\n            AND name=?;\n        ': FEHLER:  Syntaxfehler bei »;«\nLINE 8:             AND name=?;\n                              ^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mSyntaxError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2263\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2264\u001b[1;33m             \u001b[0mcur\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msql\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2265\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mcur\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mSyntaxError\u001b[0m: FEHLER:  Syntaxfehler bei »;«\nLINE 8:             AND name=?;\n                              ^\n",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13576/4130419709.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcredentials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpg_credentials\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDBManager\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcredentials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_table_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mitineraries_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'itineraries'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mdb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate_table_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraveler_pricing_df\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtable_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'traveler_pricing'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\afroj\\OneDrive\\Desktop\\Flights extension MVP\\db_manager.py\u001b[0m in \u001b[0;36mcreate_table_from_df\u001b[1;34m(self, df, table_name)\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate_table_from_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m         df.to_sql(name=table_name, con=self.connection, \n\u001b[0m\u001b[0;32m     41\u001b[0m                   index=False, if_exists='append')\n\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                 )\n\u001b[1;32m--> 333\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m         \u001b[1;31m# error: \"Callable[[VarArg(Any), KwArg(Any)], Any]\" has no\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, name, con, schema, if_exists, index, index_label, chunksize, dtype, method)\u001b[0m\n\u001b[0;32m   3006\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mpandas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mio\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msql\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3007\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3008\u001b[1;33m         return sql.to_sql(\n\u001b[0m\u001b[0;32m   3009\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3010\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(frame, name, con, schema, if_exists, index, index_label, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    787\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mpandasSQL_builder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcon\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneed_transaction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpandas_sql\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 788\u001b[1;33m         return pandas_sql.to_sql(\n\u001b[0m\u001b[0;32m    789\u001b[0m             \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    790\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mto_sql\u001b[1;34m(self, frame, name, if_exists, index, index_label, schema, chunksize, dtype, method, engine, **engine_kwargs)\u001b[0m\n\u001b[0;32m   2438\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2439\u001b[0m         )\n\u001b[1;32m-> 2440\u001b[1;33m         \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2441\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtable\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minsert\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mcreate\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    924\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mcreate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 925\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    926\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mif_exists\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"fail\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    927\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Table '{self.name}' already exists.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexists\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    909\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    910\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 911\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpd_sql\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhas_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschema\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    912\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msql_schema\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mhas_table\u001b[1;34m(self, name, schema)\u001b[0m\n\u001b[0;32m   2453\u001b[0m         \"\"\"\n\u001b[0;32m   2454\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2455\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2456\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2457\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_table\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtable_name\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mschema\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\io\\sql.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, sql, params)\u001b[0m\n\u001b[0;32m   2274\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2275\u001b[0m             \u001b[0mex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDatabaseError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Execution failed on sql '{sql}': {exc}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2276\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mex\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2277\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2278\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: Execution failed on sql '\n        SELECT\n            name\n        FROM\n            sqlite_master\n        WHERE\n            type IN ('table', 'view')\n            AND name=?;\n        ': FEHLER:  Syntaxfehler bei »;«\nLINE 8:             AND name=?;\n                              ^\n"
     ]
    }
   ],
   "source": [
    "credentials=config.pg_credentials\n",
    "db = DBManager(credentials=credentials)\n",
    "db.create_table_from_df(df=itineraries_df,table_name='public.itineraries')\n",
    "db.create_table_from_df(df=traveler_pricing_df,table_name='public.traveler_pricing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
