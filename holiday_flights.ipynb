{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\core\\computation\\expressions.py:21: UserWarning: Pandas requires version '2.8.0' or newer of 'numexpr' (version '2.7.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "c:\\Users\\afroj\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\masked.py:62: UserWarning: Pandas requires version '1.3.4' or newer of 'bottleneck' (version '1.3.2' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import config\n",
    "from db_manager import DBManager\n",
    "import os\n",
    "from rest_api import Api\n",
    "from datetime import date, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from urllib.parse import quote_plus\n",
    "from sqlalchemy import create_engine\n",
    "import itertools\n",
    "import logging\n",
    "import pickle\n",
    "import hashlib\n",
    "import gspread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(levelname)s-%(lineno)s-%(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level='INFO'\n",
    ")\n",
    "logger=logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show all columns without truncating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:2-Current date: 2023-11-10\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "logger.info(f'Current date: {today}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading Gsheet to DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Authenticate with Google Sheets\n",
    "gc = gspread.service_account(filename='service_account.json')\n",
    "\n",
    "# Open the Google Sheets spreadsheet\n",
    "worksheet = gc.open('Indian Holiday List').sheet1\n",
    "\n",
    "# Read data from Google Sheets\n",
    "data = worksheet.get_all_records()\n",
    "\n",
    "# Convert the data into a Pandas DataFrame\n",
    "gsheet_df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-db_manager:29-CONNECTED\n",
      "INFO-db_manager:68-Running DDL Query truncate_indian_festivals\n",
      "INFO-db_manager:74-Execution Completed\n",
      "INFO-db_manager:90-Dumped to DB\n"
     ]
    }
   ],
   "source": [
    "credentials=config.pg_credentials\n",
    "db = DBManager(credentials=credentials)\n",
    "db.run_etl_query(query_file_name='truncate_indian_festivals')\n",
    "db.create_table_from_df(df=gsheet_df,table_name='indian_festivals')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding months to today's date. Near term travel dates 30 - 60 days ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# departure_date_1_month = today + relativedelta(months=1)\n",
    "# departure_date_2_month = today + relativedelta(months=2)\n",
    "# return_date_1_month = departure_date_2_month\n",
    "# return_date_2_month = today + relativedelta(months=3)\n",
    "# logger.info(f'Departure_dates:{departure_date_1_month} and {departure_date_2_month} \\nReturn dates:{return_date_1_month} and {return_date_2_month}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the nearby festival departure dates by start_date from the public.indian_holidays table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-db_manager:29-CONNECTED\n",
      "INFO-db_manager:50-Running Query festival_dates_near\n",
      "INFO-db_manager:52-Execution Completed\n"
     ]
    }
   ],
   "source": [
    "credentials=config.pg_credentials\n",
    "db = DBManager(credentials=credentials)\n",
    "df_festival_near = db.run_query(query_file_name='festival_dates_near')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-db_manager:29-CONNECTED\n",
      "INFO-db_manager:50-Running Query festival_dates_far\n",
      "INFO-db_manager:52-Execution Completed\n"
     ]
    }
   ],
   "source": [
    "#appending to a list that will contain departure and arrival dates for festivals that are near and  far\n",
    "credentials=config.pg_credentials\n",
    "db = DBManager(credentials=credentials)\n",
    "df_festival_far = db.run_query(query_file_name='festival_dates_far')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_departure_arrival_dates = pd.concat([df_festival_near, df_festival_far], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>festival</th>\n",
       "      <th>departure_dates</th>\n",
       "      <th>arrival_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Christmas</td>\n",
       "      <td>2023-12-18</td>\n",
       "      <td>2024-01-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Years</td>\n",
       "      <td>2023-12-23</td>\n",
       "      <td>2024-01-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pongal</td>\n",
       "      <td>2024-01-03</td>\n",
       "      <td>2024-02-03</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    festival departure_dates arrival_dates\n",
       "0  Christmas      2023-12-18    2024-01-18\n",
       "1  New Years      2023-12-23    2024-01-23\n",
       "2     Pongal      2024-01-03    2024-02-03"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_departure_arrival_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting departure dates to a list\n",
    "departure_dates=names = df_departure_arrival_dates['departure_dates'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[datetime.date(2023, 12, 18),\n",
       " datetime.date(2023, 12, 23),\n",
       " datetime.date(2024, 1, 3)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "departure_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the combination of params to get data for all possible combinations of depart, arrival dates and depart arrival airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Travel payouts API to get flight search results for each combination in the list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API test for amadeus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POST request to the Amadeus authorization server to get the access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:6-Successful access token generation\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=config.url_token, headers=config.headers_token, data=config.data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "  # API call succeeded\n",
    "  token = response.json()['access_token'] \n",
    "  logger.info('Successful access token generation')\n",
    "else:\n",
    "  # API call failed\n",
    "  print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinations of destination and origin airport codes\n",
    "origins = config.params['originLocationCode']\n",
    "destinations = config.params['destinationLocationCode']\n",
    "departure_dates=departure_dates\n",
    "# return_dates=[return_date_1_month,return_date_2_month]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating combinations of Origin and Destination to be passed as parameters to the api call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:35-API call 1 succeeded for flight offers\n",
      "INFO-__main__:35-API call 2 succeeded for flight offers\n",
      "INFO-__main__:35-API call 3 succeeded for flight offers\n",
      "INFO-__main__:35-API call 4 succeeded for flight offers\n",
      "INFO-__main__:35-API call 5 succeeded for flight offers\n",
      "INFO-__main__:35-API call 6 succeeded for flight offers\n",
      "INFO-__main__:35-API call 7 succeeded for flight offers\n",
      "INFO-__main__:35-API call 8 succeeded for flight offers\n",
      "INFO-__main__:35-API call 9 succeeded for flight offers\n",
      "INFO-__main__:35-API call 10 succeeded for flight offers\n",
      "INFO-__main__:35-API call 11 succeeded for flight offers\n",
      "INFO-__main__:35-API call 12 succeeded for flight offers\n",
      "INFO-__main__:35-API call 13 succeeded for flight offers\n",
      "INFO-__main__:35-API call 14 succeeded for flight offers\n",
      "INFO-__main__:35-API call 15 succeeded for flight offers\n",
      "INFO-__main__:35-API call 16 succeeded for flight offers\n",
      "INFO-__main__:35-API call 17 succeeded for flight offers\n",
      "INFO-__main__:35-API call 18 succeeded for flight offers\n",
      "INFO-__main__:35-API call 19 succeeded for flight offers\n",
      "INFO-__main__:35-API call 20 succeeded for flight offers\n",
      "INFO-__main__:35-API call 21 succeeded for flight offers\n",
      "INFO-__main__:35-API call 22 succeeded for flight offers\n",
      "INFO-__main__:35-API call 23 succeeded for flight offers\n",
      "INFO-__main__:35-API call 24 succeeded for flight offers\n",
      "INFO-__main__:35-API call 25 succeeded for flight offers\n",
      "INFO-__main__:35-API call 26 succeeded for flight offers\n",
      "INFO-__main__:35-API call 27 succeeded for flight offers\n",
      "INFO-__main__:35-API call 28 succeeded for flight offers\n",
      "INFO-__main__:35-API call 29 succeeded for flight offers\n",
      "INFO-__main__:35-API call 30 succeeded for flight offers\n",
      "INFO-__main__:35-API call 31 succeeded for flight offers\n",
      "INFO-__main__:35-API call 32 succeeded for flight offers\n",
      "INFO-__main__:35-API call 33 succeeded for flight offers\n",
      "INFO-__main__:35-API call 34 succeeded for flight offers\n",
      "INFO-__main__:35-API call 35 succeeded for flight offers\n",
      "INFO-__main__:35-API call 36 succeeded for flight offers\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "  'client_id': config.client_id, \n",
    "  'client_secret': config.client_secret,\n",
    "  'Authorization': f'Bearer {token}'\n",
    "  }\n",
    "\n",
    "url = config.url\n",
    "\n",
    "response = []\n",
    "counter = 0\n",
    "\n",
    "for origin, dest, depart in itertools.product(origins, destinations, departure_dates):\n",
    "\n",
    "    params={\n",
    "        'originLocationCode': origin,\n",
    "        'destinationLocationCode':dest, \n",
    "        'departureDate': depart, \n",
    "        'returnDate' : None,\n",
    "        'adults':1,\n",
    "        'children':None,\n",
    "        'infants':None,\n",
    "        'travelClass':None,\n",
    "        'currencyCode':'EUR',\n",
    "        'maxPrice' : None\n",
    "        }\n",
    "\n",
    "\n",
    "    #to be worked on later for by calling rest_api module\n",
    "    # api = Api()\n",
    "    # resp = api.make_flight_api_request(url,headers,params)\n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    counter = counter+1\n",
    "    resp = resp.json()\n",
    "    response.append(resp)\n",
    "    logger.info(f'API call {counter} succeeded for flight offers')\n",
    "    # else:\n",
    "    #     # API call failed\n",
    "    #     logger.info('API call failed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Global variable to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the payload for real time price script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# payload = {\n",
    "#   \"data\": {\n",
    "#     \"type\": \"flight-offers-pricing\",\n",
    "#     \"flightOffers\": [], \n",
    "#     \"travelers\": []\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# for r in response:\n",
    "\n",
    "#   # Extract flight offer data\n",
    "#   offers = r['data']\n",
    "  \n",
    "#   # Add offers to payload\n",
    "#   payload['data']['flightOffers'].extend(offers) \n",
    "\n",
    "# # Convert payload to JSON string for request \n",
    "# json_payload = json.dumps(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_search_response =json_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the variable to a file\n",
    "# with open('global_variable.pkl', 'wb') as file:\n",
    "#     pickle.dump(flight_search_response, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert that sample nested JSON data into separate DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same above procedure for itineraries and traveler_pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_df = pd.DataFrame()\n",
    "\n",
    "for i in range(counter):\n",
    "    # Assuming response[i]['data'] is a dictionary\n",
    "    data_to_append = pd.json_normalize(response[i]['data'], record_path=['itineraries'], meta=['id', 'source'])\n",
    "    \n",
    "    # Append the data to the existing DataFrame\n",
    "    offer_df = pd.concat([offer_df, data_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what the offer df contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the first dept airport and last arrival airport looping through each row in itineraries df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_df['first_dept_airport'] = offer_df['segments'].apply(lambda x: x[0]['departure']['iataCode']) \n",
    "offer_df['last_arr_airport'] = offer_df['segments'].apply(lambda x: x[-1]['arrival']['iataCode'])\n",
    "offer_df['first_dept_time'] = offer_df['segments'].apply(lambda x: x[0]['departure']['at']) \n",
    "offer_df['last_arr_time'] = offer_df['segments'].apply(lambda x: x[-1]['arrival']['at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a composite key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think About a unique key that you will use to join pricing table and segments table together to get the price of the flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_df = offer_df.rename(columns={'id': 'offer_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying another unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id(row):\n",
    "    unique_string = f\"{row['offer_id']}_{row['first_dept_airport']}_{row['last_arr_airport']}_{row['first_dept_time']}_{row['last_arr_time']}\"\n",
    "    unique_id = hashlib.md5(unique_string.encode()).hexdigest()\n",
    "    return unique_id\n",
    "\n",
    "offer_df['unique_id'] = offer_df.apply(generate_unique_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_df=offer_df.drop(columns=['segments'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired column order\n",
    "desired_order = ['unique_id', 'offer_id', 'source','first_dept_airport','last_arr_airport','first_dept_time','last_arr_time','duration']\n",
    "\n",
    "# Create a new DataFrame with columns in the desired order\n",
    "offer_df = offer_df[desired_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting to datetime type\n",
    "offer_df['first_dept_time'] = pd.to_datetime(offer_df['first_dept_time'])\n",
    "offer_df['last_arr_time'] = pd.to_datetime(offer_df['last_arr_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the festival flag column that differentiates between festival dates and near future dates \n",
    "offer_df['festival_flag']=1\n",
    "# Merge the DataFrames based on the date component of \"first_dept_time\" and \"departure_dates\"\n",
    "offer_df['festival'] = offer_df['first_dept_time'].dt.date.map(df_departure_arrival_dates.set_index('departure_dates')['festival'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.now()\n",
    "offer_df['incremental_day']=now\n",
    "offer_df['incremental_day'] = pd.to_datetime(offer_df['incremental_day'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itineraries segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "itineraries_df = pd.DataFrame()\n",
    "\n",
    "for i in range(counter):\n",
    "    # Assuming response[i]['data'] is a dictionary\n",
    "    data_to_append = pd.json_normalize(response[i]['data'], record_path=['itineraries'], meta=['id', 'source'])\n",
    "    \n",
    "    # Append the data to the existing DataFrame\n",
    "    itineraries_df = pd.concat([itineraries_df, data_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "itineraries_df['first_dept_airport'] = itineraries_df['segments'].apply(lambda x: x[0]['departure']['iataCode']) \n",
    "itineraries_df['last_arr_airport'] = itineraries_df['segments'].apply(lambda x: x[-1]['arrival']['iataCode'])\n",
    "itineraries_df['first_dept_time'] = itineraries_df['segments'].apply(lambda x: x[0]['departure']['at']) \n",
    "itineraries_df['last_arr_time'] = itineraries_df['segments'].apply(lambda x: x[-1]['arrival']['at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to genearte unique id before exploding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id(row):\n",
    "    unique_string = f\"{row['id']}_{row['first_dept_airport']}_{row['last_arr_airport']}_{row['first_dept_time']}_{row['last_arr_time']}\"\n",
    "    unique_id = hashlib.md5(unique_string.encode()).hexdigest()\n",
    "    return unique_id\n",
    "\n",
    "itineraries_df['unique_id_fk'] = itineraries_df.apply(generate_unique_id, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating the itineraries df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just taking the exploded df and carefully scanning each row in the top 5 rows to see what kind of values does the exploded version of offer df contains\n",
    "exploded df\n",
    "df2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'segment' column to create separate rows for each dictionary\n",
    "exploded_df = itineraries_df.explode('segments')\n",
    "\n",
    "# Split the dictionary into columns  \n",
    "df2 = exploded_df['segments'].apply(pd.Series)\n",
    "\n",
    "# Merge the new columns back to the original DataFrame\n",
    "df = exploded_df.merge(df2, right_index=True, left_index=True, suffixes=('_original', '_segments'))\n",
    "\n",
    "# Drop the original dictionary column\n",
    "df = df.drop(columns=['segments']) \n",
    "df = df.rename(columns={'duration_original': 'duration_total','id_original':'offer_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_total</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>source</th>\n",
       "      <th>unique_id_fk</th>\n",
       "      <th>carrierCode</th>\n",
       "      <th>number</th>\n",
       "      <th>duration_segments</th>\n",
       "      <th>id_segments</th>\n",
       "      <th>numberOfStops</th>\n",
       "      <th>dept_airport</th>\n",
       "      <th>dept_at</th>\n",
       "      <th>arrival_airport</th>\n",
       "      <th>arrival_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT10H35M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>5708d1cd35002f3efb2a1bd6c4af9b1a</td>\n",
       "      <td>KL</td>\n",
       "      <td>1824</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2024-01-03T11:50:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03T13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT10H35M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>5708d1cd35002f3efb2a1bd6c4af9b1a</td>\n",
       "      <td>KL</td>\n",
       "      <td>109</td>\n",
       "      <td>PT8H15M</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03T14:10:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2024-01-04T01:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT12H15M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>989d90ffd0528dce28571e04905b4384</td>\n",
       "      <td>KL</td>\n",
       "      <td>1822</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2024-01-03T10:10:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03T11:35:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT12H15M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>989d90ffd0528dce28571e04905b4384</td>\n",
       "      <td>KL</td>\n",
       "      <td>109</td>\n",
       "      <td>PT8H15M</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03T14:10:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2024-01-04T01:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT16H25M</td>\n",
       "      <td>3</td>\n",
       "      <td>GDS</td>\n",
       "      <td>60eed3504368a77c80679e9835624ec4</td>\n",
       "      <td>KL</td>\n",
       "      <td>1818</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2024-01-03T06:00:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03T07:25:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration_total offer_id source                      unique_id_fk  \\\n",
       "0       PT10H35M        1    GDS  5708d1cd35002f3efb2a1bd6c4af9b1a   \n",
       "1       PT10H35M        1    GDS  5708d1cd35002f3efb2a1bd6c4af9b1a   \n",
       "2       PT12H15M        2    GDS  989d90ffd0528dce28571e04905b4384   \n",
       "3       PT12H15M        2    GDS  989d90ffd0528dce28571e04905b4384   \n",
       "4       PT16H25M        3    GDS  60eed3504368a77c80679e9835624ec4   \n",
       "\n",
       "  carrierCode number duration_segments id_segments  numberOfStops  \\\n",
       "0          KL   1824           PT1H25M         187              0   \n",
       "1          KL    109           PT8H15M         188              0   \n",
       "2          KL   1822           PT1H25M         117              0   \n",
       "3          KL    109           PT8H15M         118              0   \n",
       "4          KL   1818           PT1H25M         153              0   \n",
       "\n",
       "  dept_airport              dept_at arrival_airport           arrival_at  \n",
       "0          BER  2024-01-03T11:50:00             AMS  2024-01-03T13:15:00  \n",
       "1          AMS  2024-01-03T14:10:00             DEL  2024-01-04T01:55:00  \n",
       "2          BER  2024-01-03T10:10:00             AMS  2024-01-03T11:35:00  \n",
       "3          AMS  2024-01-03T14:10:00             DEL  2024-01-04T01:55:00  \n",
       "4          BER  2024-01-03T06:00:00             AMS  2024-01-03T07:25:00  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract departure keys using apply\n",
    "df['dept_airport'] = df['departure'].apply(lambda x: x['iataCode'])\n",
    "df['dept_at'] = df['departure'].apply(lambda x: x['at'])\n",
    "df['arrival_airport'] = df['arrival'].apply(lambda x: x['iataCode'])\n",
    "df['arrival_at'] = df['arrival'].apply(lambda x: x['at'])\n",
    "df['aircraft'] = df['aircraft'].apply(lambda x: x['code'])\n",
    "df.head()\n",
    "# Drop stops column if it exists\n",
    "column_to_drop = 'stops'\n",
    "if column_to_drop in df.columns:\n",
    "    df.drop(column_to_drop,axis=1,inplace=True)\n",
    "itineraries_df = df.drop(columns=['departure','arrival','operating','aircraft','blacklistedInEU','first_dept_airport','last_arr_airport','first_dept_time','last_arr_time'])\n",
    "\n",
    "itineraries_df = itineraries_df.drop_duplicates()\n",
    "# Reset index\n",
    "itineraries_df = itineraries_df.reset_index(drop=True)\n",
    "itineraries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "itineraries_df['segment_key'] = itineraries_df['unique_id_fk'].astype(str) + '_' + itineraries_df['id_segments'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create unique id for segments df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming, reordering and changing datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns according to the SQL table schema\n",
    "itineraries_df = itineraries_df.rename(columns={\n",
    "    'source': 'source',\n",
    "    'duration_segments': 'duration_segments',\n",
    "    'duration_total': 'duration_total',\n",
    "    'carrierCode': 'carrier_code',\n",
    "    'number': 'number',\n",
    "    'duration_segments': 'duration_segments',\n",
    "    'numberOfStops': 'number_of_stops',\n",
    "    'dept_airport': 'dept_airport',\n",
    "    'dept_at': 'dept_at',\n",
    "    'arrival_airport': 'arrival_airport',\n",
    "    'arrival_at': 'arrival_at'\n",
    "})\n",
    "\n",
    "# Ensure data types are set correctly\n",
    "itineraries_df['offer_id'] = itineraries_df['offer_id'].astype(int)\n",
    "itineraries_df['number_of_stops'] = itineraries_df['number_of_stops'].astype(int)\n",
    "itineraries_df['dept_at'] = pd.to_datetime(itineraries_df['dept_at'])\n",
    "itineraries_df['arrival_at'] = pd.to_datetime(itineraries_df['arrival_at'])\n",
    "\n",
    "now = datetime.now()\n",
    "itineraries_df['incremental_day']=now\n",
    "itineraries_df['incremental_day'] = pd.to_datetime(itineraries_df['incremental_day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:1-Current date: 2023-11-10 08:33:44.026936\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Current date: {now}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming itineraries_df is your DataFrame\n",
    "new_column_order = [\n",
    "    'segment_key',\n",
    "    'duration_total',\n",
    "    'offer_id',\n",
    "    'source',\n",
    "    'unique_id_fk',\n",
    "    'carrier_code',\n",
    "    'number',\n",
    "    'duration_segments',\n",
    "    'id_segments',\n",
    "    'number_of_stops',\n",
    "    'dept_airport',\n",
    "    'dept_at',\n",
    "    'arrival_airport',\n",
    "    'arrival_at',\n",
    "    'incremental_day'\n",
    "]\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "itineraries_df = itineraries_df[new_column_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_key</th>\n",
       "      <th>duration_total</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>source</th>\n",
       "      <th>unique_id_fk</th>\n",
       "      <th>carrier_code</th>\n",
       "      <th>number</th>\n",
       "      <th>duration_segments</th>\n",
       "      <th>id_segments</th>\n",
       "      <th>number_of_stops</th>\n",
       "      <th>dept_airport</th>\n",
       "      <th>dept_at</th>\n",
       "      <th>arrival_airport</th>\n",
       "      <th>arrival_at</th>\n",
       "      <th>incremental_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5708d1cd35002f3efb2a1bd6c4af9b1a_187</td>\n",
       "      <td>PT10H35M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>5708d1cd35002f3efb2a1bd6c4af9b1a</td>\n",
       "      <td>KL</td>\n",
       "      <td>1824</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2024-01-03 11:50:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03 13:15:00</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5708d1cd35002f3efb2a1bd6c4af9b1a_188</td>\n",
       "      <td>PT10H35M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>5708d1cd35002f3efb2a1bd6c4af9b1a</td>\n",
       "      <td>KL</td>\n",
       "      <td>109</td>\n",
       "      <td>PT8H15M</td>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03 14:10:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2024-01-04 01:55:00</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>989d90ffd0528dce28571e04905b4384_117</td>\n",
       "      <td>PT12H15M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>989d90ffd0528dce28571e04905b4384</td>\n",
       "      <td>KL</td>\n",
       "      <td>1822</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2024-01-03 10:10:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03 11:35:00</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>989d90ffd0528dce28571e04905b4384_118</td>\n",
       "      <td>PT12H15M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>989d90ffd0528dce28571e04905b4384</td>\n",
       "      <td>KL</td>\n",
       "      <td>109</td>\n",
       "      <td>PT8H15M</td>\n",
       "      <td>118</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03 14:10:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2024-01-04 01:55:00</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60eed3504368a77c80679e9835624ec4_153</td>\n",
       "      <td>PT16H25M</td>\n",
       "      <td>3</td>\n",
       "      <td>GDS</td>\n",
       "      <td>60eed3504368a77c80679e9835624ec4</td>\n",
       "      <td>KL</td>\n",
       "      <td>1818</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2024-01-03 06:00:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2024-01-03 07:25:00</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            segment_key duration_total  offer_id source  \\\n",
       "0  5708d1cd35002f3efb2a1bd6c4af9b1a_187       PT10H35M         1    GDS   \n",
       "1  5708d1cd35002f3efb2a1bd6c4af9b1a_188       PT10H35M         1    GDS   \n",
       "2  989d90ffd0528dce28571e04905b4384_117       PT12H15M         2    GDS   \n",
       "3  989d90ffd0528dce28571e04905b4384_118       PT12H15M         2    GDS   \n",
       "4  60eed3504368a77c80679e9835624ec4_153       PT16H25M         3    GDS   \n",
       "\n",
       "                       unique_id_fk carrier_code number duration_segments  \\\n",
       "0  5708d1cd35002f3efb2a1bd6c4af9b1a           KL   1824           PT1H25M   \n",
       "1  5708d1cd35002f3efb2a1bd6c4af9b1a           KL    109           PT8H15M   \n",
       "2  989d90ffd0528dce28571e04905b4384           KL   1822           PT1H25M   \n",
       "3  989d90ffd0528dce28571e04905b4384           KL    109           PT8H15M   \n",
       "4  60eed3504368a77c80679e9835624ec4           KL   1818           PT1H25M   \n",
       "\n",
       "  id_segments  number_of_stops dept_airport             dept_at  \\\n",
       "0         187                0          BER 2024-01-03 11:50:00   \n",
       "1         188                0          AMS 2024-01-03 14:10:00   \n",
       "2         117                0          BER 2024-01-03 10:10:00   \n",
       "3         118                0          AMS 2024-01-03 14:10:00   \n",
       "4         153                0          BER 2024-01-03 06:00:00   \n",
       "\n",
       "  arrival_airport          arrival_at            incremental_day  \n",
       "0             AMS 2024-01-03 13:15:00 2023-11-10 08:33:44.026936  \n",
       "1             DEL 2024-01-04 01:55:00 2023-11-10 08:33:44.026936  \n",
       "2             AMS 2024-01-03 11:35:00 2023-11-10 08:33:44.026936  \n",
       "3             DEL 2024-01-04 01:55:00 2023-11-10 08:33:44.026936  \n",
       "4             AMS 2024-01-03 07:25:00 2023-11-10 08:33:44.026936  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itineraries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment key unique check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer = pd.DataFrame()\n",
    "\n",
    "for i in range(counter):\n",
    "    # Assuming response[i]['data'] is a dictionary\n",
    "    data_to_append = pd.json_normalize(response[i]['data'], meta=['id', 'source'])\n",
    "    \n",
    "    # Append the data to the existing DataFrame\n",
    "    offer = pd.concat([offer, data_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df = pd.DataFrame()\n",
    "\n",
    "for i in range(counter):\n",
    "    # Assuming response[i]['data'] is a dictionary\n",
    "    data_to_append = pd.json_normalize(response[i]['data'], meta=['id', 'source'])\n",
    "    \n",
    "    # Append the data to the existing DataFrame\n",
    "    pricing_df = pd.concat([pricing_df, data_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df = pricing_df.drop(columns=['instantTicketingRequired','nonHomogeneous','oneWay','lastTicketingDate','lastTicketingDateTime','numberOfBookableSeats','validatingAirlineCodes','travelerPricings'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first departure airport\n",
    "pricing_df['first_dept_airport'] = pricing_df['itineraries'].apply(lambda x: x[0]['segments'][0]['departure']['iataCode'])\n",
    "\n",
    "# Extract last arrival airport\n",
    "pricing_df['last_arr_airport'] = pricing_df['itineraries'].apply(lambda x: x[0]['segments'][-1]['arrival']['iataCode'])\n",
    "\n",
    "# Extract first departure time\n",
    "pricing_df['first_dept_time'] = pricing_df['itineraries'].apply(lambda x: x[0]['segments'][0]['departure']['at'])\n",
    "\n",
    "# Extract last arrival time\n",
    "pricing_df['last_arr_time'] = pricing_df['itineraries'].apply(lambda x: x[0]['segments'][-1]['arrival']['at'])\n",
    "\n",
    "# Drop the 'itineraries' column if no longer needed\n",
    "pricing_df.drop(columns=['itineraries'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id(row):\n",
    "    unique_string = f\"{row['id']}_{row['first_dept_airport']}_{row['last_arr_airport']}_{row['first_dept_time']}_{row['last_arr_time']}\"\n",
    "    unique_id = hashlib.md5(unique_string.encode()).hexdigest()\n",
    "    return unique_id\n",
    "\n",
    "pricing_df['unique_id_fk'] = pricing_df.apply(generate_unique_id, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove \"price\" and dots from column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df = pricing_df.rename(columns=lambda x: x.replace('price.', '').replace('price', ''))\n",
    "pricing_df = pricing_df.rename(columns=lambda x: x.replace('pricingOptions.', '').replace('price', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'additionalServices' into two columns\n",
    "pricing_df = pricing_df.drop(['additionalServices','fees','type','id','source','first_dept_time','last_arr_time','last_arr_airport','first_dept_airport'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pricing_df['incremental_day'] =now\n",
    "pricing_df['incremental_day'] = pd.to_datetime(pricing_df['incremental_day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df.rename(columns={'grandTotal': 'grand_total','fareType': 'fare_type','includedCheckedBagsOnly': 'included_checkedbags_only'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>currency</th>\n",
       "      <th>total</th>\n",
       "      <th>base</th>\n",
       "      <th>grand_total</th>\n",
       "      <th>fare_type</th>\n",
       "      <th>included_checkedbags_only</th>\n",
       "      <th>unique_id_fk</th>\n",
       "      <th>incremental_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>5708d1cd35002f3efb2a1bd6c4af9b1a</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>989d90ffd0528dce28571e04905b4384</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>60eed3504368a77c80679e9835624ec4</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>36c7ec92630eecd5469b28e6135bc743</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>1af4088dceef67051970516419ee4507</td>\n",
       "      <td>2023-11-10 08:33:44.026936</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  currency   total    base grand_total    fare_type  \\\n",
       "0      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "1      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "2      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "3      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "4      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "\n",
       "   included_checkedbags_only                      unique_id_fk  \\\n",
       "0                      False  5708d1cd35002f3efb2a1bd6c4af9b1a   \n",
       "1                      False  989d90ffd0528dce28571e04905b4384   \n",
       "2                      False  60eed3504368a77c80679e9835624ec4   \n",
       "3                      False  36c7ec92630eecd5469b28e6135bc743   \n",
       "4                      False  1af4088dceef67051970516419ee4507   \n",
       "\n",
       "             incremental_day  \n",
       "0 2023-11-10 08:33:44.026936  \n",
       "1 2023-11-10 08:33:44.026936  \n",
       "2 2023-11-10 08:33:44.026936  \n",
       "3 2023-11-10 08:33:44.026936  \n",
       "4 2023-11-10 08:33:44.026936  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pricing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-db_manager:29-CONNECTED\n",
      "INFO-db_manager:90-Dumped to DB\n",
      "INFO-db_manager:90-Dumped to DB\n",
      "INFO-db_manager:90-Dumped to DB\n"
     ]
    }
   ],
   "source": [
    "credentials=config.pg_credentials\n",
    "db = DBManager(credentials=credentials)\n",
    "db.create_table_from_df(df=offer_df,table_name='flight_offers')\n",
    "db.create_table_from_df(df=itineraries_df,table_name='itineraries')\n",
    "db.create_table_from_df(df=pricing_df,table_name='pricing')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
