{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import config\n",
    "from db_manager import DBManager\n",
    "import os\n",
    "from rest_api import Api\n",
    "from datetime import date, datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from urllib.parse import quote_plus\n",
    "from sqlalchemy import create_engine\n",
    "import itertools\n",
    "import logging\n",
    "import pickle\n",
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(\n",
    "    format='%(levelname)s-%(lineno)s-%(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level='INFO'\n",
    ")\n",
    "logger=logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Show all columns without truncating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Today's date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:2-Current date: 2023-11-05\n"
     ]
    }
   ],
   "source": [
    "today = date.today()\n",
    "logger.info(f'Current date: {today}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding months to today's date. Near term travel dates 30 - 60 days ahead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:5-Departure_dates:2023-12-05 and 2024-01-05 \n",
      "Return dates:2024-01-05 and 2024-02-05\n"
     ]
    }
   ],
   "source": [
    "departure_date_1_month = today + relativedelta(months=1)\n",
    "departure_date_2_month = today + relativedelta(months=2)\n",
    "return_date_1_month = departure_date_2_month\n",
    "return_date_2_month = today + relativedelta(months=3)\n",
    "logger.info(f'Departure_dates:{departure_date_1_month} and {departure_date_2_month} \\nReturn dates:{return_date_1_month} and {return_date_2_month}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the nearby festival departure dates by start_date from the public.indian_holidays table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# credentials=config.pg_credentials\n",
    "# db = DBManager(credentials=credentials)\n",
    "# df_departure_arrival_dates = db.run_query(query_file_name='festival_dates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_departure_arrival_dates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply the combination of params to get data for all possible combinations of depart, arrival dates and depart arrival airports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combination itertools usage. Im calculating the total combinations by multiplying the number of possibilities (unique values) for each variable<br />\n",
    "Departure airport: 2 possibilities<br />\n",
    "Arrival airport: 4 possibilities<br />\n",
    "Departure date: 2 possibilities<br />\n",
    "Arrival date: 1 possibilities<br />\n",
    "Total combinations = 2 x 4 x 2 x 1 = 16 combinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Travel payouts API to get flight search results for each combination in the list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API test for amadeus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POST request to the Amadeus authorization server to get the access token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:6-Successful access token generation\n"
     ]
    }
   ],
   "source": [
    "response = requests.post(url=config.url_token, headers=config.headers_token, data=config.data)\n",
    "\n",
    "if response.status_code == 200:\n",
    "  # API call succeeded\n",
    "  token = response.json()['access_token'] \n",
    "  logger.info('Successful access token generation')\n",
    "else:\n",
    "  # API call failed\n",
    "  print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combinations of destination and origin airport codes\n",
    "origins = config.params['originLocationCode']\n",
    "destinations = config.params['destinationLocationCode']\n",
    "departure_dates=[departure_date_1_month,departure_date_2_month]\n",
    "# return_dates=[return_date_1_month,return_date_2_month]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating combinations of Origin and Destination to be passed as parameters to the api call"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:35-API call 1 succeeded for flight offers\n",
      "INFO-__main__:35-API call 2 succeeded for flight offers\n",
      "INFO-__main__:35-API call 3 succeeded for flight offers\n",
      "INFO-__main__:35-API call 4 succeeded for flight offers\n",
      "INFO-__main__:35-API call 5 succeeded for flight offers\n",
      "INFO-__main__:35-API call 6 succeeded for flight offers\n",
      "INFO-__main__:35-API call 7 succeeded for flight offers\n",
      "INFO-__main__:35-API call 8 succeeded for flight offers\n",
      "INFO-__main__:35-API call 9 succeeded for flight offers\n",
      "INFO-__main__:35-API call 10 succeeded for flight offers\n",
      "INFO-__main__:35-API call 11 succeeded for flight offers\n",
      "INFO-__main__:35-API call 12 succeeded for flight offers\n",
      "INFO-__main__:35-API call 13 succeeded for flight offers\n",
      "INFO-__main__:35-API call 14 succeeded for flight offers\n",
      "INFO-__main__:35-API call 15 succeeded for flight offers\n",
      "INFO-__main__:35-API call 16 succeeded for flight offers\n",
      "INFO-__main__:35-API call 17 succeeded for flight offers\n",
      "INFO-__main__:35-API call 18 succeeded for flight offers\n",
      "INFO-__main__:35-API call 19 succeeded for flight offers\n",
      "INFO-__main__:35-API call 20 succeeded for flight offers\n",
      "INFO-__main__:35-API call 21 succeeded for flight offers\n",
      "INFO-__main__:35-API call 22 succeeded for flight offers\n",
      "INFO-__main__:35-API call 23 succeeded for flight offers\n",
      "INFO-__main__:35-API call 24 succeeded for flight offers\n"
     ]
    }
   ],
   "source": [
    "headers = {\n",
    "  'client_id': config.client_id, \n",
    "  'client_secret': config.client_secret,\n",
    "  'Authorization': f'Bearer {token}'\n",
    "  }\n",
    "\n",
    "url = config.url\n",
    "\n",
    "response = []\n",
    "counter = 0\n",
    "\n",
    "for origin, dest, depart in itertools.product(origins, destinations, departure_dates):\n",
    "\n",
    "    params={\n",
    "        'originLocationCode': origin,\n",
    "        'destinationLocationCode':dest, \n",
    "        'departureDate': depart, \n",
    "        'returnDate' : None,\n",
    "        'adults':1,\n",
    "        'children':None,\n",
    "        'infants':None,\n",
    "        'travelClass':None,\n",
    "        'currencyCode':'EUR',\n",
    "        'maxPrice' : None\n",
    "        }\n",
    "\n",
    "\n",
    "    #to be worked on later for by calling rest_api module\n",
    "    # api = Api()\n",
    "    # resp = api.make_flight_api_request(url,headers,params)\n",
    "    resp = requests.get(url, headers=headers, params=params)\n",
    "    counter = counter+1\n",
    "    resp = resp.json()\n",
    "    response.append(resp)\n",
    "    logger.info(f'API call {counter} succeeded for flight offers')\n",
    "    # else:\n",
    "    #     # API call failed\n",
    "    #     logger.info('API call failed')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the Global variable to a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the payload for real time price script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# payload = {\n",
    "#   \"data\": {\n",
    "#     \"type\": \"flight-offers-pricing\",\n",
    "#     \"flightOffers\": [], \n",
    "#     \"travelers\": []\n",
    "#   }\n",
    "# }\n",
    "\n",
    "# for r in response:\n",
    "\n",
    "#   # Extract flight offer data\n",
    "#   offers = r['data']\n",
    "  \n",
    "#   # Add offers to payload\n",
    "#   payload['data']['flightOffers'].extend(offers) \n",
    "\n",
    "# # Convert payload to JSON string for request \n",
    "# json_payload = json.dumps(payload)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flight_search_response =json_payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the variable to a file\n",
    "# with open('global_variable.pkl', 'wb') as file:\n",
    "#     pickle.dump(flight_search_response, file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert that sample nested JSON data into separate DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repeat the same above procedure for itineraries and traveler_pricing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Offers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_df = pd.DataFrame()\n",
    "\n",
    "for i in range(24):\n",
    "    # Assuming response[i]['data'] is a dictionary\n",
    "    data_to_append = pd.json_normalize(response[i]['data'], record_path=['itineraries'], meta=['id', 'source'])\n",
    "    \n",
    "    # Append the data to the existing DataFrame\n",
    "    offer_df = pd.concat([offer_df, data_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking what the offer df contains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get the first dept airport and last arrival airport looping through each row in itineraries df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_df['first_dept_airport'] = offer_df['segments'].apply(lambda x: x[0]['departure']['iataCode']) \n",
    "offer_df['last_arr_airport'] = offer_df['segments'].apply(lambda x: x[-1]['arrival']['iataCode'])\n",
    "offer_df['first_dept_time'] = offer_df['segments'].apply(lambda x: x[0]['departure']['at']) \n",
    "offer_df['last_arr_time'] = offer_df['segments'].apply(lambda x: x[-1]['arrival']['at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating a composite key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think About a unique key that you will use to join pricing table and segments table together to get the price of the flight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_df = offer_df.rename(columns={'id': 'offer_id'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying another unique id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id(row):\n",
    "    unique_string = f\"{row['offer_id']}_{row['first_dept_airport']}_{row['last_arr_airport']}_{row['first_dept_time']}_{row['last_arr_time']}\"\n",
    "    unique_id = hashlib.md5(unique_string.encode()).hexdigest()\n",
    "    return unique_id\n",
    "\n",
    "offer_df['unique_id'] = offer_df.apply(generate_unique_id, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_df=offer_df.drop(columns=['segments'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the desired column order\n",
    "desired_order = ['unique_id', 'offer_id', 'source','first_dept_airport','last_arr_airport','first_dept_time','last_arr_time','duration']\n",
    "\n",
    "# Create a new DataFrame with columns in the desired order\n",
    "offer_df = offer_df[desired_order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>unique_id</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>source</th>\n",
       "      <th>first_dept_airport</th>\n",
       "      <th>last_arr_airport</th>\n",
       "      <th>first_dept_time</th>\n",
       "      <th>last_arr_time</th>\n",
       "      <th>duration</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2075</th>\n",
       "      <td>46ea482110caf821a34376ab382ced51</td>\n",
       "      <td>78</td>\n",
       "      <td>GDS</td>\n",
       "      <td>MUC</td>\n",
       "      <td>MAA</td>\n",
       "      <td>2024-01-05T11:00:00</td>\n",
       "      <td>2024-01-05T23:00:00</td>\n",
       "      <td>PT7H30M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2076</th>\n",
       "      <td>fad9604dace84a83a9a6698ff4aebb0a</td>\n",
       "      <td>79</td>\n",
       "      <td>GDS</td>\n",
       "      <td>MUC</td>\n",
       "      <td>MAA</td>\n",
       "      <td>2024-01-05T11:10:00</td>\n",
       "      <td>2024-01-05T23:00:00</td>\n",
       "      <td>PT7H20M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>f214dc50b41a134209eca106e3bdd1d4</td>\n",
       "      <td>80</td>\n",
       "      <td>GDS</td>\n",
       "      <td>MUC</td>\n",
       "      <td>MAA</td>\n",
       "      <td>2024-01-05T09:10:00</td>\n",
       "      <td>2024-01-05T23:00:00</td>\n",
       "      <td>PT9H20M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2078</th>\n",
       "      <td>e4003355b1be87bcff88406733df3e5d</td>\n",
       "      <td>81</td>\n",
       "      <td>GDS</td>\n",
       "      <td>MUC</td>\n",
       "      <td>MAA</td>\n",
       "      <td>2024-01-05T08:05:00</td>\n",
       "      <td>2024-01-05T23:00:00</td>\n",
       "      <td>PT10H25M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2079</th>\n",
       "      <td>53b6e6d97b4973895870b531eaa045dc</td>\n",
       "      <td>82</td>\n",
       "      <td>GDS</td>\n",
       "      <td>MUC</td>\n",
       "      <td>MAA</td>\n",
       "      <td>2024-01-05T21:45:00</td>\n",
       "      <td>2024-01-06T13:30:00</td>\n",
       "      <td>PT11H15M</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             unique_id offer_id source first_dept_airport  \\\n",
       "2075  46ea482110caf821a34376ab382ced51       78    GDS                MUC   \n",
       "2076  fad9604dace84a83a9a6698ff4aebb0a       79    GDS                MUC   \n",
       "2077  f214dc50b41a134209eca106e3bdd1d4       80    GDS                MUC   \n",
       "2078  e4003355b1be87bcff88406733df3e5d       81    GDS                MUC   \n",
       "2079  53b6e6d97b4973895870b531eaa045dc       82    GDS                MUC   \n",
       "\n",
       "     last_arr_airport      first_dept_time        last_arr_time  duration  \n",
       "2075              MAA  2024-01-05T11:00:00  2024-01-05T23:00:00   PT7H30M  \n",
       "2076              MAA  2024-01-05T11:10:00  2024-01-05T23:00:00   PT7H20M  \n",
       "2077              MAA  2024-01-05T09:10:00  2024-01-05T23:00:00   PT9H20M  \n",
       "2078              MAA  2024-01-05T08:05:00  2024-01-05T23:00:00  PT10H25M  \n",
       "2079              MAA  2024-01-05T21:45:00  2024-01-06T13:30:00  PT11H15M  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "offer_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Itineraries segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itineraries_df = pd.DataFrame()\n",
    "\n",
    "for i in range(24):\n",
    "    # Assuming response[i]['data'] is a dictionary\n",
    "    data_to_append = pd.json_normalize(response[i]['data'], record_path=['itineraries'], meta=['id', 'source'])\n",
    "    \n",
    "    # Append the data to the existing DataFrame\n",
    "    itineraries_df = pd.concat([itineraries_df, data_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itineraries_df['first_dept_airport'] = itineraries_df['segments'].apply(lambda x: x[0]['departure']['iataCode']) \n",
    "itineraries_df['last_arr_airport'] = itineraries_df['segments'].apply(lambda x: x[-1]['arrival']['iataCode'])\n",
    "itineraries_df['first_dept_time'] = itineraries_df['segments'].apply(lambda x: x[0]['departure']['at']) \n",
    "itineraries_df['last_arr_time'] = itineraries_df['segments'].apply(lambda x: x[-1]['arrival']['at'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trying to genearte unique id before exploding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id(row):\n",
    "    unique_string = f\"{row['id']}_{row['first_dept_airport']}_{row['last_arr_airport']}_{row['first_dept_time']}_{row['last_arr_time']}\"\n",
    "    unique_id = hashlib.md5(unique_string.encode()).hexdigest()\n",
    "    return unique_id\n",
    "\n",
    "itineraries_df['unique_id_fk'] = itineraries_df.apply(generate_unique_id, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Treating the itineraries df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just taking the exploded df and carefully scanning each row in the top 5 rows to see what kind of values does the exploded version of offer df contains\n",
    "exploded df\n",
    "df2\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explode the 'segment' column to create separate rows for each dictionary\n",
    "exploded_df = itineraries_df.explode('segments')\n",
    "\n",
    "# Split the dictionary into columns  \n",
    "df2 = exploded_df['segments'].apply(pd.Series)\n",
    "\n",
    "# Merge the new columns back to the original DataFrame\n",
    "df = exploded_df.merge(df2, right_index=True, left_index=True, suffixes=('_original', '_segments'))\n",
    "\n",
    "# Drop the original dictionary column\n",
    "df = df.drop(columns=['segments']) \n",
    "df = df.rename(columns={'duration_original': 'duration_total','id_original':'offer_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration_total</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>source</th>\n",
       "      <th>unique_id_fk</th>\n",
       "      <th>carrierCode</th>\n",
       "      <th>number</th>\n",
       "      <th>duration_segments</th>\n",
       "      <th>id_segments</th>\n",
       "      <th>numberOfStops</th>\n",
       "      <th>dept_airport</th>\n",
       "      <th>dept_at</th>\n",
       "      <th>arrival_airport</th>\n",
       "      <th>arrival_at</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PT10H35M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>7cbbb21d4e8e94e90668e6ab656eaaf2</td>\n",
       "      <td>KL</td>\n",
       "      <td>1824</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2023-12-05T11:50:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05T13:15:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PT10H35M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>7cbbb21d4e8e94e90668e6ab656eaaf2</td>\n",
       "      <td>KL</td>\n",
       "      <td>109</td>\n",
       "      <td>PT8H15M</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05T14:10:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2023-12-06T01:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PT16H25M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>b66001f51ad00ed9f592f32d5e64bb81</td>\n",
       "      <td>KL</td>\n",
       "      <td>1818</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2023-12-05T06:00:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05T07:25:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PT16H25M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>b66001f51ad00ed9f592f32d5e64bb81</td>\n",
       "      <td>KL</td>\n",
       "      <td>109</td>\n",
       "      <td>PT8H15M</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05T14:10:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2023-12-06T01:55:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PT25H15M</td>\n",
       "      <td>3</td>\n",
       "      <td>GDS</td>\n",
       "      <td>759e075afd7882db4d165ca69d0bd4eb</td>\n",
       "      <td>KL</td>\n",
       "      <td>1834</td>\n",
       "      <td>PT1H30M</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2023-12-05T21:10:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05T22:40:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  duration_total offer_id source                      unique_id_fk  \\\n",
       "0       PT10H35M        1    GDS  7cbbb21d4e8e94e90668e6ab656eaaf2   \n",
       "1       PT10H35M        1    GDS  7cbbb21d4e8e94e90668e6ab656eaaf2   \n",
       "2       PT16H25M        2    GDS  b66001f51ad00ed9f592f32d5e64bb81   \n",
       "3       PT16H25M        2    GDS  b66001f51ad00ed9f592f32d5e64bb81   \n",
       "4       PT25H15M        3    GDS  759e075afd7882db4d165ca69d0bd4eb   \n",
       "\n",
       "  carrierCode number duration_segments id_segments  numberOfStops  \\\n",
       "0          KL   1824           PT1H25M         100              0   \n",
       "1          KL    109           PT8H15M         101              0   \n",
       "2          KL   1818           PT1H25M          82              0   \n",
       "3          KL    109           PT8H15M          83              0   \n",
       "4          KL   1834           PT1H30M          61              0   \n",
       "\n",
       "  dept_airport              dept_at arrival_airport           arrival_at  \n",
       "0          BER  2023-12-05T11:50:00             AMS  2023-12-05T13:15:00  \n",
       "1          AMS  2023-12-05T14:10:00             DEL  2023-12-06T01:55:00  \n",
       "2          BER  2023-12-05T06:00:00             AMS  2023-12-05T07:25:00  \n",
       "3          AMS  2023-12-05T14:10:00             DEL  2023-12-06T01:55:00  \n",
       "4          BER  2023-12-05T21:10:00             AMS  2023-12-05T22:40:00  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract departure keys using apply\n",
    "df['dept_airport'] = df['departure'].apply(lambda x: x['iataCode'])\n",
    "df['dept_at'] = df['departure'].apply(lambda x: x['at'])\n",
    "df['arrival_airport'] = df['arrival'].apply(lambda x: x['iataCode'])\n",
    "df['arrival_at'] = df['arrival'].apply(lambda x: x['at'])\n",
    "df['aircraft'] = df['aircraft'].apply(lambda x: x['code'])\n",
    "df.head()\n",
    "# Drop stops column if it exists\n",
    "column_to_drop = 'stops'\n",
    "if column_to_drop in df.columns:\n",
    "    df.drop(column_to_drop,axis=1,inplace=True)\n",
    "itineraries_df = df.drop(columns=['departure','arrival','operating','aircraft','blacklistedInEU','first_dept_airport','last_arr_airport','first_dept_time','last_arr_time'])\n",
    "\n",
    "itineraries_df = itineraries_df.drop_duplicates()\n",
    "# Reset index\n",
    "itineraries_df = itineraries_df.reset_index(drop=True)\n",
    "itineraries_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "itineraries_df['segment_key'] = itineraries_df['unique_id_fk'].astype(str) + '_' + itineraries_df['id_segments'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create unique id for segments df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renaming, reordering and changing datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the columns according to the SQL table schema\n",
    "itineraries_df = itineraries_df.rename(columns={\n",
    "    'source': 'source',\n",
    "    'duration_segments': 'duration_segments',\n",
    "    'duration_total': 'duration_total',\n",
    "    'carrierCode': 'carrier_code',\n",
    "    'number': 'number',\n",
    "    'duration_segments': 'duration_segments',\n",
    "    'numberOfStops': 'number_of_stops',\n",
    "    'dept_airport': 'dept_airport',\n",
    "    'dept_at': 'dept_at',\n",
    "    'arrival_airport': 'arrival_airport',\n",
    "    'arrival_at': 'arrival_at'\n",
    "})\n",
    "\n",
    "# Ensure data types are set correctly\n",
    "itineraries_df['offer_id'] = itineraries_df['offer_id'].astype(int)\n",
    "itineraries_df['number_of_stops'] = itineraries_df['number_of_stops'].astype(int)\n",
    "itineraries_df['dept_at'] = pd.to_datetime(itineraries_df['dept_at'])\n",
    "itineraries_df['arrival_at'] = pd.to_datetime(itineraries_df['arrival_at'])\n",
    "\n",
    "now = datetime.now()\n",
    "itineraries_df['incremental_day']=now\n",
    "itineraries_df['incremental_day'] = pd.to_datetime(itineraries_df['incremental_day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-__main__:1-Current date: 2023-11-05 20:23:55.149435\n"
     ]
    }
   ],
   "source": [
    "logger.info(f'Current date: {now}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming itineraries_df is your DataFrame\n",
    "new_column_order = [\n",
    "    'segment_key',\n",
    "    'duration_total',\n",
    "    'offer_id',\n",
    "    'source',\n",
    "    'unique_id_fk',\n",
    "    'carrier_code',\n",
    "    'number',\n",
    "    'duration_segments',\n",
    "    'id_segments',\n",
    "    'number_of_stops',\n",
    "    'dept_airport',\n",
    "    'dept_at',\n",
    "    'arrival_airport',\n",
    "    'arrival_at',\n",
    "    'incremental_day'\n",
    "]\n",
    "\n",
    "# Reorder the DataFrame columns\n",
    "itineraries_df = itineraries_df[new_column_order]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment_key</th>\n",
       "      <th>duration_total</th>\n",
       "      <th>offer_id</th>\n",
       "      <th>source</th>\n",
       "      <th>unique_id_fk</th>\n",
       "      <th>carrier_code</th>\n",
       "      <th>number</th>\n",
       "      <th>duration_segments</th>\n",
       "      <th>id_segments</th>\n",
       "      <th>number_of_stops</th>\n",
       "      <th>dept_airport</th>\n",
       "      <th>dept_at</th>\n",
       "      <th>arrival_airport</th>\n",
       "      <th>arrival_at</th>\n",
       "      <th>incremental_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7cbbb21d4e8e94e90668e6ab656eaaf2_100</td>\n",
       "      <td>PT10H35M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>7cbbb21d4e8e94e90668e6ab656eaaf2</td>\n",
       "      <td>KL</td>\n",
       "      <td>1824</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2023-12-05 11:50:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05 13:15:00</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7cbbb21d4e8e94e90668e6ab656eaaf2_101</td>\n",
       "      <td>PT10H35M</td>\n",
       "      <td>1</td>\n",
       "      <td>GDS</td>\n",
       "      <td>7cbbb21d4e8e94e90668e6ab656eaaf2</td>\n",
       "      <td>KL</td>\n",
       "      <td>109</td>\n",
       "      <td>PT8H15M</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05 14:10:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2023-12-06 01:55:00</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b66001f51ad00ed9f592f32d5e64bb81_82</td>\n",
       "      <td>PT16H25M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>b66001f51ad00ed9f592f32d5e64bb81</td>\n",
       "      <td>KL</td>\n",
       "      <td>1818</td>\n",
       "      <td>PT1H25M</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2023-12-05 06:00:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05 07:25:00</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b66001f51ad00ed9f592f32d5e64bb81_83</td>\n",
       "      <td>PT16H25M</td>\n",
       "      <td>2</td>\n",
       "      <td>GDS</td>\n",
       "      <td>b66001f51ad00ed9f592f32d5e64bb81</td>\n",
       "      <td>KL</td>\n",
       "      <td>109</td>\n",
       "      <td>PT8H15M</td>\n",
       "      <td>83</td>\n",
       "      <td>0</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05 14:10:00</td>\n",
       "      <td>DEL</td>\n",
       "      <td>2023-12-06 01:55:00</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>759e075afd7882db4d165ca69d0bd4eb_61</td>\n",
       "      <td>PT25H15M</td>\n",
       "      <td>3</td>\n",
       "      <td>GDS</td>\n",
       "      <td>759e075afd7882db4d165ca69d0bd4eb</td>\n",
       "      <td>KL</td>\n",
       "      <td>1834</td>\n",
       "      <td>PT1H30M</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>BER</td>\n",
       "      <td>2023-12-05 21:10:00</td>\n",
       "      <td>AMS</td>\n",
       "      <td>2023-12-05 22:40:00</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            segment_key duration_total  offer_id source  \\\n",
       "0  7cbbb21d4e8e94e90668e6ab656eaaf2_100       PT10H35M         1    GDS   \n",
       "1  7cbbb21d4e8e94e90668e6ab656eaaf2_101       PT10H35M         1    GDS   \n",
       "2   b66001f51ad00ed9f592f32d5e64bb81_82       PT16H25M         2    GDS   \n",
       "3   b66001f51ad00ed9f592f32d5e64bb81_83       PT16H25M         2    GDS   \n",
       "4   759e075afd7882db4d165ca69d0bd4eb_61       PT25H15M         3    GDS   \n",
       "\n",
       "                       unique_id_fk carrier_code number duration_segments  \\\n",
       "0  7cbbb21d4e8e94e90668e6ab656eaaf2           KL   1824           PT1H25M   \n",
       "1  7cbbb21d4e8e94e90668e6ab656eaaf2           KL    109           PT8H15M   \n",
       "2  b66001f51ad00ed9f592f32d5e64bb81           KL   1818           PT1H25M   \n",
       "3  b66001f51ad00ed9f592f32d5e64bb81           KL    109           PT8H15M   \n",
       "4  759e075afd7882db4d165ca69d0bd4eb           KL   1834           PT1H30M   \n",
       "\n",
       "  id_segments  number_of_stops dept_airport             dept_at  \\\n",
       "0         100                0          BER 2023-12-05 11:50:00   \n",
       "1         101                0          AMS 2023-12-05 14:10:00   \n",
       "2          82                0          BER 2023-12-05 06:00:00   \n",
       "3          83                0          AMS 2023-12-05 14:10:00   \n",
       "4          61                0          BER 2023-12-05 21:10:00   \n",
       "\n",
       "  arrival_airport          arrival_at            incremental_day  \n",
       "0             AMS 2023-12-05 13:15:00 2023-11-05 20:23:55.149435  \n",
       "1             DEL 2023-12-06 01:55:00 2023-11-05 20:23:55.149435  \n",
       "2             AMS 2023-12-05 07:25:00 2023-11-05 20:23:55.149435  \n",
       "3             DEL 2023-12-06 01:55:00 2023-11-05 20:23:55.149435  \n",
       "4             AMS 2023-12-05 22:40:00 2023-11-05 20:23:55.149435  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "itineraries_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segment key unique check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding out which columns in a dataframe are lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming deduplicated_df is your DataFrame\n",
    "# list_columns = []\n",
    "\n",
    "# for column in final_df.columns:\n",
    "#     if final_df[column].apply(lambda x: isinstance(x, list)).any():\n",
    "#         list_columns.append(column)\n",
    "\n",
    "# print(\"Columns with lists:\", list_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pricing flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "offer = pd.DataFrame()\n",
    "\n",
    "for i in range(24):\n",
    "    # Assuming response[i]['data'] is a dictionary\n",
    "    data_to_append = pd.json_normalize(response[i]['data'], meta=['id', 'source'])\n",
    "    \n",
    "    # Append the data to the existing DataFrame\n",
    "    offer = pd.concat([offer, data_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df = pd.DataFrame()\n",
    "\n",
    "for i in range(24):\n",
    "    # Assuming response[i]['data'] is a dictionary\n",
    "    data_to_append = pd.json_normalize(response[i]['data'], meta=['id', 'source'])\n",
    "    \n",
    "    # Append the data to the existing DataFrame\n",
    "    pricing_df = pd.concat([pricing_df, data_to_append], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df = pricing_df.drop(columns=['instantTicketingRequired','nonHomogeneous','oneWay','lastTicketingDate','lastTicketingDateTime','numberOfBookableSeats','validatingAirlineCodes','travelerPricings'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract first departure airport\n",
    "pricing_df['first_dept_airport'] = pricing_df['itineraries'].apply(lambda x: x[0]['segments'][0]['departure']['iataCode'])\n",
    "\n",
    "# Extract last arrival airport\n",
    "pricing_df['last_arr_airport'] = pricing_df['itineraries'].apply(lambda x: x[0]['segments'][-1]['arrival']['iataCode'])\n",
    "\n",
    "# Extract first departure time\n",
    "pricing_df['first_dept_time'] = pricing_df['itineraries'].apply(lambda x: x[0]['segments'][0]['departure']['at'])\n",
    "\n",
    "# Extract last arrival time\n",
    "pricing_df['last_arr_time'] = pricing_df['itineraries'].apply(lambda x: x[0]['segments'][-1]['arrival']['at'])\n",
    "\n",
    "# Drop the 'itineraries' column if no longer needed\n",
    "pricing_df.drop(columns=['itineraries'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_unique_id(row):\n",
    "    unique_string = f\"{row['id']}_{row['first_dept_airport']}_{row['last_arr_airport']}_{row['first_dept_time']}_{row['last_arr_time']}\"\n",
    "    unique_id = hashlib.md5(unique_string.encode()).hexdigest()\n",
    "    return unique_id\n",
    "\n",
    "pricing_df['unique_id_fk'] = pricing_df.apply(generate_unique_id, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove \"price\" and dots from column names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df = pricing_df.rename(columns=lambda x: x.replace('price.', '').replace('price', ''))\n",
    "pricing_df = pricing_df.rename(columns=lambda x: x.replace('pricingOptions.', '').replace('price', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 'additionalServices' into two columns\n",
    "pricing_df = pricing_df.drop(['additionalServices','fees','type','id','source','first_dept_time','last_arr_time','last_arr_airport','first_dept_airport'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "pricing_df['incremental_day'] =now\n",
    "pricing_df['incremental_day'] = pd.to_datetime(pricing_df['incremental_day'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pricing_df.rename(columns={'grandTotal': 'grand_total','fareType': 'fare_type','includedCheckedBagsOnly': 'included_checkedbags_only'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>currency</th>\n",
       "      <th>total</th>\n",
       "      <th>base</th>\n",
       "      <th>grand_total</th>\n",
       "      <th>fare_type</th>\n",
       "      <th>included_checkedbags_only</th>\n",
       "      <th>unique_id_fk</th>\n",
       "      <th>incremental_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>7cbbb21d4e8e94e90668e6ab656eaaf2</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>b66001f51ad00ed9f592f32d5e64bb81</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>759e075afd7882db4d165ca69d0bd4eb</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>abd39e59d1bd6c1c39533f08076862ea</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EUR</td>\n",
       "      <td>479.48</td>\n",
       "      <td>259.00</td>\n",
       "      <td>479.48</td>\n",
       "      <td>[PUBLISHED]</td>\n",
       "      <td>False</td>\n",
       "      <td>9bad770401e165eaaef6af4522d9e5c8</td>\n",
       "      <td>2023-11-05 20:23:55.149435</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  currency   total    base grand_total    fare_type  \\\n",
       "0      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "1      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "2      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "3      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "4      EUR  479.48  259.00      479.48  [PUBLISHED]   \n",
       "\n",
       "   included_checkedbags_only                      unique_id_fk  \\\n",
       "0                      False  7cbbb21d4e8e94e90668e6ab656eaaf2   \n",
       "1                      False  b66001f51ad00ed9f592f32d5e64bb81   \n",
       "2                      False  759e075afd7882db4d165ca69d0bd4eb   \n",
       "3                      False  abd39e59d1bd6c1c39533f08076862ea   \n",
       "4                      False  9bad770401e165eaaef6af4522d9e5c8   \n",
       "\n",
       "             incremental_day  \n",
       "0 2023-11-05 20:23:55.149435  \n",
       "1 2023-11-05 20:23:55.149435  \n",
       "2 2023-11-05 20:23:55.149435  \n",
       "3 2023-11-05 20:23:55.149435  \n",
       "4 2023-11-05 20:23:55.149435  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pricing_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO-db_manager:27-CONNECTED\n",
      "INFO-db_manager:73-Dumped to DB\n",
      "INFO-db_manager:73-Dumped to DB\n",
      "INFO-db_manager:73-Dumped to DB\n"
     ]
    }
   ],
   "source": [
    "credentials=config.pg_credentials\n",
    "db = DBManager(credentials=credentials)\n",
    "db.create_table_from_df(df=offer_df,table_name='flight_offers')\n",
    "db.create_table_from_df(df=itineraries_df,table_name='itineraries')\n",
    "db.create_table_from_df(df=pricing_df,table_name='pricing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
